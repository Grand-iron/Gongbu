Signate컵 참가 후기

성과 : 상위 약 3.7% 성적 달성

사용한 모델 : xgboost (완성 모델 및 코드 = 최종 모델 비교 폴더 참조)
선택 이유 : 캐글에 비슷한 대회에서 가장 많이 수상한 부스팅 모델로서 그렇기에 많은 참고 자료들을 접할 수 있었다. 그리고 각 모델들을 그리드 서치를 통해 하이퍼 파라미터를 바꿔가며 비교하는 과정을 거쳤을때 가장 실 성능이 좋았기에 xgboost를 바탕으로 상세 조정을 하게 되었다.

데이터 셋 간단 정보: 결과값이 6:1 불균형, 비선형 데이터, 결측치와 이상값 존재, train 데이터 수가 약 3500개로 적은 편, 컬럼은 약 20개 (base 폴더 base_pipeline 파일 참조)

다른 후보 모델 간단 소개 및 채택되지 못한 이유 (각 모델 하이퍼파라미터 base 폴더 모델명 파일 정리)
catboost (대칭 트리 구조의 형태로 범주형 변수를 자동으로 처리할 수 있는 능력이 탑재 / xgboost에 비해 부족한 하이퍼파라미터 수, train 데이터가 6:1로 불균형 했기에 대칭 트리구조인 catboost는 부적합 하다고 판단)
LGBM (비대칭 트리구조로 GOSS와 EFB기법이 추가되어 빠른 학습 시간과 적은 메모리 사용량을 보인다. / 데이터 수가 적기에 과접합이 발생하는 단점이 있어서 제외)
elastic_net (L1 및 L2 정규화를 결합한 회귀 기법 / 다양한 변수들의 상호작용을 모델링 하는 과정의 번거로움, 비선형 데이터에 대한 성능의 아쉬움)
svc (데이터 포인트를 최적의 초평면으로 분리하여 분류하는 기계 학습 알고리즘 / 비선형 데이터에 대한 성능의 아쉬움, 하이퍼 파라미터에 민감하여 최적을 뽑아내야 하는데 시간적, 효율적으로 부적합 하다고 판단)

아쉬운 점 : 수상을 목표로 했지만 수상을 하지 못한 아쉬움이 있다.
좋았던 점 : 팀원과 협업하여 그래도 성과를 얻어내서 좋은 것 같고 부스팅기법을 포함한 다양한 모델들을 다뤄보고 실제와 같은 오류 및 변수가 가득한 데이터 처리를 해보며 재밌었던 것 같다. 